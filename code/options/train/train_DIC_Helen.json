{
    "name": "Helen_DIY_aug_Attention_FBHG_with_distort",
    "_comment": "68 face landmarks, connect HG over steps by feature average between each stacks",
    "mode": "sr_align",
    "gpu_ids": [0, 1],
    "use_tb_logger": true,
    "scale": 8,
    "is_train": true,
    "rgb_range": 1,
    "save_image": true,
    "datasets": {
        "train": {
            "mode": "HRLandmark",
            "name": "HelenLandmarkTrain",
            "dataroot_HR": "/home/jzy/datasets/SR_datasets/Helen/img_helen",
            "info_path": "/home/jzy/datasets/SR_datasets/Helen/train_info_list_68.pkl", 
            "data_type": "img",
            "n_workers": 16,
            "batch_size": 8,
            "LR_size": 16,
            "HR_size": 128,
            "distort": [0.66, 1.33],
            "use_flip": true,
            "use_rot": true,
            "sigma": 1
        },
        "val": {
            "mode": "HRLandmark",
            "name": "HelenLandmarkVal",
            "dataroot_HR": "/home/jzy/datasets/SR_datasets/Helen/img_helen",
            "info_path": "/home/jzy/datasets/SR_datasets/Helen/test_info_list_68.pkl",
            "data_type": "img",
            "LR_size": 16,
            "HR_size": 128,
            "sigma": 1
        }
    },
    "networks": {
        "which_model": "SRFBN_HG_V5",
        "num_features": 48,
        "in_channels": 3,
        "out_channels": 3,
        "num_steps": 4,
        "num_groups": 6,
        "detach_attention": false,
        "hg_num_feature": 256,
        "hg_num_keypoints": 68,
        "num_fusion_block": 7
    },
    "solver": {
        "type": "ADAM",
        "learning_rate": 1e-4,
        "weight_decay": 0,
        "lr_scheme": "MultiStepLR",
        "lr_steps": [
            5e3, 1e4, 2e4
        ],
        "lr_gamma": 0.5,
        "manual_seed": 0,
        "save_freq": 5e3,
        "val_freq": 1e3,
        "niter": 2e5,
        "num_save_image": 20,
        "log_full_step": true,
        "pretrain": "resume",
        "pretrained_path": "../experiments/SRFBN_HG_V5_in3f48_x8_Helen_DIY_aug_Attention_FBHG_with_distort/epochs/step_0100000_ckp.pth",
        "HG_pretrained_path": "../models/FB_HG_68_CelebA.pth",
        "release_HG_grad_step": 3e4,
        "loss": {
            "pixel": {
                "loss_type": "l1",
                "weight": 1
            },
            "align": {
                "loss_type": "l2",
                "weight": 1e-1
            }
        }
    },
    "logger": {
        "print_freq": 200
    },
    "path": {
      "root": "/home/jzy/projects/Feedback-Attention-FaceSR"
    }
}

